{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "be8b445e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be8b445e",
        "outputId": "b620e223-b161-4e2b-ab13-db0ea2bd3d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow #Thư viện chính cho các nhiệm vụ deep learning.\n",
        "import tensorflow as tf\n",
        "#Các mô-đun này chứa các hàm và lớp để tạo các mô hình mạng thần kinh.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "#Chứa các chức năng tiện ích\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#Bao gồm các công cụ để xử lý trước dữ liệu, chẳng hạn như thay đổi kích thước và tăng kích thước hình ảnh.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#Các gói cơ bản cho tính toán khoa học và thao tác dữ liệu.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Mô hình VGG16 được đào tạo trước, được sử dụng để tận dụng việc học chuyển giao.\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import  Model\n",
        "import matplotlib.pyplot as plt #Thư viện để tạo trực quan hóa tĩnh, tương tác và hoạt hình trong Python.\n",
        "#Cụ thể, train_test_splitđược sử dụng để phân chia dữ liệu thành các tập huấn luyện và kiểm tra.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm #Thư viện hiển thị thanh tiến trình trong vòng lặp.\n",
        "import cv2 #Thư viện OpenCV để xử lý ảnh.\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cfd86a5f",
      "metadata": {
        "id": "cfd86a5f"
      },
      "outputs": [],
      "source": [
        "#xác định các hằng số cho chiều rộng hình ảnh ( IMAGE_W) và chiều cao ( IMAGE_H), cả hai đều được đặt thành 224 pixel.\n",
        "#Các kích thước này thường được sử dụng cho hình ảnh đầu vào trong các mô hình học sâu, đặc biệt là trong các mô hình dựa trên mạng thần kinh tích chập (CNN) được thiết kế cho các tác vụ nhận dạng hình ảnh.\n",
        "IMAGE_W = 224\n",
        "IMAGE_H = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e0b3bf79",
      "metadata": {
        "id": "e0b3bf79"
      },
      "outputs": [],
      "source": [
        "#Import và tạo VGG16 base model\n",
        "#VGG16: Là một mô hình kiến trúc mạng CNN (Convolutional Neural Network) sâu phổ biến.\n",
        "#weights='imagenet': Sử dụng trọng số được huấn luyện trước trên tập dữ liệu ImageNet.\n",
        "#include_top=False: Loại bỏ các lớp fully connected ở cuối mô hình, vì chúng ta sẽ tự định nghĩa các lớp này phù hợp với bài toán cụ thể của mình.\n",
        "def get_model():\n",
        "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "    # Dong bang cac layer\n",
        "    # Đóng băng các lớp của mô hình VGG16\n",
        "    # Điều này đảm bảo rằng các trọng số của mô hình VGG16 sẽ không được cập nhật trong quá trình huấn luyện. Mục tiêu là sử dụng mô hình này như một bộ trích xuất đặc trưng.\n",
        "    for layer in model_vgg16_conv.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Tao model\n",
        "    # Tạo đầu vào và đầu ra của mô hình\n",
        "    input = Input(shape=(IMAGE_W, IMAGE_H, 3), name='image_input') #Input: Tạo tensor đầu vào với kích thước ảnh (IMAGE_W, IMAGE_H, 3), ở đây 3 là số kênh màu.\n",
        "    output_vgg16_conv = model_vgg16_conv(input) #output_vgg16_conv: Lấy đầu ra từ mô hình VGG16.\n",
        "\n",
        "    # Them cac layer FC va Dropout\n",
        "    # Thêm các lớp Fully Connected và Dropout\n",
        "    x = Flatten(name='flatten')(output_vgg16_conv) #Flatten: Chuyển đổi output từ 3D sang 1D.\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x) #Dense: Các lớp fully connected với 4096 nút, sử dụng hàm kích hoạt relu.\n",
        "    x = Dropout(0.5)(x) #Dropout: Ngăn chặn hiện tượng overfitting bằng cách ngẫu nhiên loại bỏ (drop) một số nút trong mạng.\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(5, activation='sigmoid', name='predictions')(x) #Lớp cuối cùng sử dụng hàm sigmoid cho mỗi nút vì đây là bài toán phân loại nhiều lớp (multi-label classification) với 5 lớp.\n",
        "\n",
        "    # Compile\n",
        "    my_model = Model(inputs=input, outputs=x)\n",
        "    my_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['BinaryAccuracy'])\n",
        "    #binary_crossentropy: Hàm mất mát thích hợp cho bài toán phân loại nhị phân.\n",
        "    #adam: Một thuật toán tối ưu hóa hiệu quả.\n",
        "    #BinaryAccuracy: Độ chính xác nhị phân sẽ được sử dụng làm chỉ số đánh giá.\n",
        "    return my_model\n",
        "\n",
        "model = get_model() #hàm get_model() trả về mô hình đã được compile và sẵn sàng để huấn luyện. Mô hình này có thể được sử dụng để phân loại ảnh vào một trong năm lớp được định nghĩa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9413153b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "9413153b",
        "outputId": "2a59e94c-03eb-43d0-a7af-1d26c325d7a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      Filenames  desert  mountains  sea  sunset  trees\n",
              "0        1.jpg       1          0    0       0      0\n",
              "1        2.jpg       1          0    0       0      0\n",
              "2        3.jpg       1          0    0       0      0\n",
              "3        4.jpg       1          1    0       0      0\n",
              "4        5.jpg       1          0    0       0      0\n",
              "...        ...     ...        ...  ...     ...    ...\n",
              "1995  1996.jpg       0          0    0       0      1\n",
              "1996  1997.jpg       0          0    0       0      1\n",
              "1997  1998.jpg       0          0    0       0      1\n",
              "1998  1999.jpg       0          0    0       0      1\n",
              "1999  2000.jpg       0          0    0       0      1\n",
              "\n",
              "[2000 rows x 6 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.head</b><br/>def head(n: int=5) -&gt; Self</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py</a>Return the first `n` rows.\n",
              "\n",
              "This function returns the first `n` rows for the object based\n",
              "on position. It is useful for quickly testing if your object\n",
              "has the right type of data in it.\n",
              "\n",
              "For negative values of `n`, this function returns all rows except\n",
              "the last `|n|` rows, equivalent to ``df[:n]``.\n",
              "\n",
              "If n is larger than the number of rows, this function returns all rows.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "n : int, default 5\n",
              "    Number of rows to select.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "same type as caller\n",
              "    The first `n` rows of the caller object.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.tail: Returns the last `n` rows.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;animal&#x27;: [&#x27;alligator&#x27;, &#x27;bee&#x27;, &#x27;falcon&#x27;, &#x27;lion&#x27;,\n",
              "...                    &#x27;monkey&#x27;, &#x27;parrot&#x27;, &#x27;shark&#x27;, &#x27;whale&#x27;, &#x27;zebra&#x27;]})\n",
              "&gt;&gt;&gt; df\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "5     parrot\n",
              "6      shark\n",
              "7      whale\n",
              "8      zebra\n",
              "\n",
              "Viewing the first 5 lines\n",
              "\n",
              "&gt;&gt;&gt; df.head()\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "\n",
              "Viewing the first `n` lines (three in this case)\n",
              "\n",
              "&gt;&gt;&gt; df.head(3)\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "\n",
              "For negative values of `n`\n",
              "\n",
              "&gt;&gt;&gt; df.head(-3)\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "5     parrot</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5818);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "csv_file = \"/content/gdrive/MyDrive/Dataset/luanai_dataset/luanai_labels_1.csv\"\n",
        "image_path =\"/content/gdrive/MyDrive/Dataset/luanai_dataset/images\"\n",
        "# Read the CSV file\n",
        "train = pd.read_csv(csv_file)\n",
        "train.head #train.head() trả về năm hàng đầu tiên của DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "71da887a",
      "metadata": {
        "id": "71da887a"
      },
      "outputs": [],
      "source": [
        "class Dataloader(tf.keras.utils.Sequence): #định nghĩa một lớp mới có tên Dataloader kế thừa từ lớp tf.keras.utils.Sequence trong thư viện TensorFlow/Keras.\n",
        "    #Phương thức khởi tạo __init__ nhận ba tham số: dataset (tập dữ liệu), batch_size (kích thước batch), và size (kích thước tập dữ liệu).\n",
        "    #Các tham số này được gán cho các thuộc tính self.dataset, self.batch_size, và self.size tương ứng.\n",
        "    def __init__(self, dataset, batch_size, size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.size = size\n",
        "    #Phương thức __getitem__ nhận một tham số i và trả về một batch dữ liệu tại vị trí index i.\n",
        "    #Đầu tiên, nó tính toán chỉ số start và stop để xác định phạm vi của batch. Sau đó, nó duyệt qua phạm vi này và thêm các mẫu dữ liệu tương ứng vào danh sách data.\n",
        "    def __getitem__(self, i):\n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "        #sử dụng np.stack để đóng gói các mẫu dữ liệu trong data thành các mảng numpy theo chiều axis=0. Cuối cùng, nó trả về một tuple chứa các mảng numpy này.\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "        return tuple(batch)\n",
        "    #Phương thức __len__ trả về số lượng batch trong tập dữ liệu bằng cách chia kích thước tập dữ liệu self.size cho kích thước batch self.batch_size.\n",
        "    def __len__(self):\n",
        "        return self.size // self.batch_size\n",
        "\n",
        "class Dataset: #định nghĩa một lớp mới có tên Dataset\n",
        "    #khởi tạo __init__ nhận bốn tham số: data (danh sách đường dẫn của ảnh), label (danh sách đường dẫn của ảnh phân đoạn), w và h (kích thước của ảnh).\n",
        "    #Các tham số này được gán cho các thuộc tính self.data, self.label, self.w, và self.h tương ứng.\n",
        "    def __init__(self, data, label, w, h):\n",
        "        # the paths of images\n",
        "        self.data = data\n",
        "        # the paths of segmentation images\n",
        "        self.label = label\n",
        "        self.w = w\n",
        "        self.h = h\n",
        "    #Phương thức __len__ trả về kích thước của tập dữ liệu bằng cách lấy độ dài của danh sách self.data.\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i): #Phương thức __getitem__ nhận một tham số i và trả về một mẫu dữ liệu tại vị trí index i\n",
        "        # read data\n",
        "        #đọc ảnh từ đường dẫn image_path + '/' + str(self.data[i][0]) với kích thước mục tiêu (IMAGE_W, IMAGE_H, 3) bằng cách sử dụng image.load_img\n",
        "        img = image.load_img(image_path + '/' + str(self.data[i][0]),target_size=(IMAGE_W,IMAGE_H,3))\n",
        "        #chuyển đổi ảnh sang mảng numpy bằng image.img_to_array và tiến hành chuẩn hóa giá trị pixel trong khoảng [0, 1] bằng cách chia cho 255\n",
        "        img = image.img_to_array(img)\n",
        "        img = img /255\n",
        "        #lấy nhãn phân đoạn tương ứng từ danh sách self.label và trả về cả ảnh và nhãn dưới dạng tuple.\n",
        "        label = self.label[i]\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "865fb3db",
      "metadata": {
        "id": "865fb3db"
      },
      "outputs": [],
      "source": [
        "y = np.array(train.drop(columns=[\"Filenames\"])) #tạo ra một DataFrame mới từ train bằng cách loại bỏ cột có tên \"Filenames\".\n",
        "X = np.array(train) #chuyển đổi DataFrame đó thành một mảng NumPy. Kết quả được gán cho biến y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c9858d26",
      "metadata": {
        "id": "c9858d26"
      },
      "outputs": [],
      "source": [
        "# và y là các mảng NumPy chứa dữ liệu đầu vào và nhãn tương ứng\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1) #gọi hàm train_test_split\n",
        "#X và y là dữ liệu đầu vào và nhãn cần chia.\n",
        "#random_state=42 đặt một giá trị seed để đảm bảo tính lặp lại trong quá trình chia ngẫu nhiên.\n",
        "#test_size=0.1 nghĩa là 10% dữ liệu sẽ được sử dụng làm tập kiểm tra, còn lại 90% là tập huấn luyện.\n",
        "#Hàm train_test_split trả về bốn mảng NumPy:\n",
        "#X_train: Dữ liệu đầu vào cho tập huấn luyện.\n",
        "#X_test: Dữ liệu đầu vào cho tập kiểm tra.\n",
        "#y_train: Nhãn cho tập huấn luyện.\n",
        "#y_test: Nhãn cho tập kiểm tra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0acc8662",
      "metadata": {
        "id": "0acc8662"
      },
      "outputs": [],
      "source": [
        "# Xay dung dataset va Dataloader\n",
        "# Build dataaset\n",
        "train_dataset = Dataset(X_train, y_train, IMAGE_W, IMAGE_H) #Tạo một đối tượng Dataset mới với tên train_dataset cho tập dữ liệu huấn luyện.\n",
        "test_dataset = Dataset(X_test, y_test, IMAGE_W, IMAGE_H) #tạo một đối tượng Dataset mới với tên test_dataset cho tập dữ liệu kiểm tra.\n",
        "\n",
        "# Loader\n",
        "#Tạo một đối tượng Dataloader mới với tên train_loader cho tập dữ liệu huấn luyện.\n",
        "train_loader = Dataloader(train_dataset, 64, len(train_dataset)) #64 là kích thước của batch, len(train_dataset) là kích thước của tập dữ liệu huấn luyện.\n",
        "test_loader = Dataloader(test_dataset, 64, len(test_dataset)) #tạo một đối tượng Dataloader mới với tên test_loader cho tập dữ liệu kiểm tra.\n",
        "#train_loader và test_loader sẽ được sử dụng trong quá trình huấn luyện và đánh giá mô hình. Cung cấp cách tải dữ liệu hiệu quả bằng cách chia thành các batch, giúp tiết kiệm bộ nhớ và tăng tốc độ xử lý."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9bd61e",
      "metadata": {
        "id": "bf9bd61e"
      },
      "outputs": [],
      "source": [
        "# Use fit method instead of fit_generator\n",
        "model.fit(train_loader, epochs=20, validation_data=test_loader) #epochs=10 chỉ định số lần lặp lại quá trình huấn luyện trên toàn bộ dữ liệu huấn luyện.\n",
        "model.save(\"/content/gdrive/MyDrive/Dataset/luanai_dataset/model.h5\")\n",
        "#validation_data=test_loader cung cấp dữ liệu kiểm tra cho mô hình để đánh giá sau mỗi epoch. test_loader là một đối tượng Dataloader chứa dữ liệu kiểm tra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_nrcTmZ1vCOM",
      "metadata": {
        "id": "_nrcTmZ1vCOM"
      },
      "outputs": [],
      "source": [
        "tf.keras.models.load_model(\"/content/gdrive/MyDrive/Dataset/luanai_dataset/model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb47e14",
      "metadata": {
        "id": "aeb47e14"
      },
      "outputs": [],
      "source": [
        "img = image.load_img(\"/content/gdrive/MyDrive/Dataset/luanai_dataset/test/img-test01.jpg\", target_size=(IMAGE_W,IMAGE_H,3)) #target_size=(IMAGE_W, IMAGE_H, 3) chỉ định kích thước mục tiêu của ảnh đầu vào.\n",
        "img = image.img_to_array(img) #Chuyển đổi đối tượng ảnh img thành một mảng NumPy bằng cách sử dụng hàm image.img_to_array.\n",
        "img = img/255 #Chuẩn hóa giá trị pixel của ảnh trong khoảng từ 0 đến 1 bằng cách chia cho 255 (giá trị pixel tối đa).\n",
        "#Thêm một chiều mới vào đầu mảng img bằng cách sử dụng hàm np.expand_dims.\n",
        "tensor = np.expand_dims(img, axis=0) #axis=0 chỉ định rằng chiều mới sẽ được thêm vào đầu\n",
        "#Kết quả là một tensor 4 chiều với hình dạng (1, IMAGE_H, IMAGE_W, 3), trong đó 1 là kích thước batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb9a993",
      "metadata": {
        "id": "afb9a993"
      },
      "outputs": [],
      "source": [
        "#tensor là tensor ảnh đầu vào đã được chuẩn bị sẵn sàng cho việc dự đoán.\n",
        "y_pred = model.predict(tensor)#predict là một phương thức của mô hình, cho phép dự đoán nhãn hoặc giá trị đầu ra cho một tensor đầu vào.\n",
        "y_pred #in ra giá trị của y_pred để kiểm tra kết quả dự đoán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac7bf6e",
      "metadata": {
        "id": "5ac7bf6e"
      },
      "outputs": [],
      "source": [
        "classes = np.array(train.columns[1:])\n",
        "\n",
        "top_3 = np.argsort(y_pred[0])[:-4:-1]\n",
        "top_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e17a3ded",
      "metadata": {
        "id": "e17a3ded"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(y_pred[0][top_3[i]] * 100))\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(\"/content/gdrive/MyDrive/Dataset/luanai_dataset/test/img-test02.jpg\", target_size=(IMAGE_W, IMAGE_H, 3))\n",
        "img = image.img_to_array(img) / 255\n",
        "tensor = np.expand_dims(img, axis=0)\n",
        "\n",
        "y_pred = model.predict(tensor)\n",
        "classes = np.array(train.columns[1:])\n",
        "top_3 = np.argsort(y_pred[0])[:-4:-1]\n",
        "\n",
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]]) + \" ({:.3})\".format(y_pred[0][top_3[i]] * 100))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "RFAKO6LId9Q7"
      },
      "id": "RFAKO6LId9Q7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(\"/content/gdrive/MyDrive/Dataset/luanai_dataset/test/img-test03.jpg\", target_size=(IMAGE_W, IMAGE_H, 3))\n",
        "img = image.img_to_array(img) / 255\n",
        "tensor = np.expand_dims(img, axis=0)\n",
        "\n",
        "y_pred = model.predict(tensor)\n",
        "classes = np.array(train.columns[1:])\n",
        "top_3 = np.argsort(y_pred[0])[:-4:-1]\n",
        "\n",
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]]) + \" ({:.3})\".format(y_pred[0][top_3[i]] * 100))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "z_ccujMzePKr"
      },
      "id": "z_ccujMzePKr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(\"/content/gdrive/MyDrive/Dataset/luanai_dataset/test/img-test04.jpg\", target_size=(IMAGE_W, IMAGE_H, 3))\n",
        "img = image.img_to_array(img) / 255\n",
        "tensor = np.expand_dims(img, axis=0)\n",
        "\n",
        "y_pred = model.predict(tensor)\n",
        "classes = np.array(train.columns[1:])\n",
        "top_3 = np.argsort(y_pred[0])[:-4:-1]\n",
        "\n",
        "for i in range(3):\n",
        "    print(\"{}\".format(classes[top_3[i]]) + \" ({:.3})\".format(y_pred[0][top_3[i]] * 100))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "AnXsGu8eeQzL"
      },
      "id": "AnXsGu8eeQzL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}